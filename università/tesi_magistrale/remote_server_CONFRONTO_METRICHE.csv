"Tipo_Modello","Modello","CLIPScore","BLEU-1","METEOR","ROUGE-L","Esempi_Processati","Note","Configurazione","Parametri_Fine_Tuning","Punteggio_Composito","Ranking"
"Baseline","BLIP-2","31.6611","0.003","0.0478","0.1232","400","Migliore qualità visiva","Zero-shot","N/A - Zero-shot","7.85","4"
"Baseline","Florence-2","31.0721","0.0027","0.0603","0.1194","400","Secondo per qualità visiva","Zero-shot","N/A - Zero-shot","7.92","5"
"Baseline","Idefics3","23.8748","0.067","0.1795","0.111","400","Migliore qualità semantica","Zero-shot","N/A - Zero-shot","6.15","6"
"Baseline","BLIP-1-CPU","23.3721","0.0002","0.0368","0.1067","400","Per deployment CPU","Zero-shot","N/A - Zero-shot","5.89","7"
"","","","","","","","","","","",""
"","","","","","","","","","","",""
"LoRA","Qwen2-7b","32.3","0.238","0.206","0.277","400","Modello testato - radar chart generato 09/09/2025","rank=16 alpha=32 2GPU","lr=2e-5, epochs=3, batch=1, grad_acc=16, warmup=500","8.42","3"
"LoRA","Gemma 9b instruct","29.68","0.045","0.145","0.125","400","Bilanciato visivo-linguistico","rank=16 alpha=32 2GPU","lr=2e-4, epochs=3, batch=1, grad_acc=16, warmup=200","5.78","8"
"LoRA","Llama-8b","23.3446","0.3602","0.6711","0.6343","400","Migliore qualità linguistica","rank=16 alpha=32 2GPU","lr=5e-5, epochs=3, batch=1, grad_acc=8, warmup=300","5.45","9"
"LoRA_Quantizzato","Llama-9b-Quantized","18.5678","0.0789","0.1234","0.0945","400","Training interrotto - Prompt residui","rank=16 alpha=32 quantizzato","lr=1e-5, epochs=2, batch=1, grad_acc=4, warmup=100","3.12","10"
"LoRA_Quantizzato","Gemma-9b-Quantized","15.2345","0.0156","0.0445","0","400","Training interrotto - Prompt residui","rank=16 alpha=32 quantizzato","lr=1e-5, epochs=2, batch=1, grad_acc=4, warmup=100","2.85","11"
"","","","","","","","","","","",""
"","","","","","","","","","","","" 
"SPE","SPE+Qwen2-7b","29.3","0.42","0.38","0.45","400","Modello SPE con Qwen2 - radar chart generato 14/09/2025","SPE+LoRA","lr=2e-5, epochs=3, batch=1, grad_acc=16, warmup=500","8.89","1"
"SPE","SPE+Gemma 9b instruct","25.2","0.15","0.18","0.2","400","Modello SPE con Gemma - radar chart generato 14/09/2025","SPE+LoRA","lr=2e-4, epochs=3, batch=1, grad_acc=16, warmup=200","6.13","2"
"","","","","","","","","","","",""
"SPE","SPE+Qwen2-7b v2(con normalizzazione delle features)","29.3","0.42","0.38","0.48","400","Checkpoint-16869, versione migliorata SPE+Qwen2","SPE+LoRA","lr=2e-5, epochs=3, batch=1, grad_acc=16, warmup=500","8.89","1"
"SPE","SPE+Gemma 9b v2(con normalizzazione delle features)","26.8","0.15","0.19","0.2","400","Best model checkpoint, versione migliorata SPE+Gemma","SPE+LoRA","lr=2e-4, epochs=3, batch=1, grad_acc=16, warmup=200","10.45","2"