\babel@toc {english}{}\relax 
\contentsline {chapter}{Abstract}{5}{chapter*.2}%
\contentsline {chapter}{Sommario}{6}{chapter*.3}%
\contentsline {chapter}{\numberline {1}Introduction}{7}{chapter.1}%
\contentsline {section}{\numberline {1.1}The Challenge of Vector Graphics Captioning}{8}{section.1.1}%
\contentsline {section}{\numberline {1.2}Accessibility, Search, and the Need for Automatic Captions}{9}{section.1.2}%
\contentsline {section}{\numberline {1.3}Research Hypothesis: Treating SVG as a Structured Language}{10}{section.1.3}%
\contentsline {section}{\numberline {1.4}The Role of Large Language Models in the Proposed Approach}{11}{section.1.4}%
\contentsline {section}{\numberline {1.5}Parameter-Efficient Fine-Tuning with LoRA}{11}{section.1.5}%
\contentsline {section}{\numberline {1.6}The SVG Path Embedder: Bridging Geometry and Language}{12}{section.1.6}%
\contentsline {section}{\numberline {1.7}Research Objectives}{13}{section.1.7}%
\contentsline {section}{\numberline {1.8}Summary of Methodology and Key Findings}{13}{section.1.8}%
\contentsline {section}{\numberline {1.9}Thesis Organization}{14}{section.1.9}%
\contentsline {chapter}{\numberline {2}State of the Art}{15}{chapter.2}%
\contentsline {section}{\numberline {2.1}Foundations: Transformers and Self-Attention}{15}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}The Transformer Architecture}{15}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}SVG and the Tokenization Challenge}{16}{subsection.2.1.2}%
\contentsline {section}{\numberline {2.2}Large Language Models: Evolution to Decoder-Only Architectures}{16}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}From BERT to GPT: Encoder vs. Decoder}{16}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Modern Decoder-Only LLMs}{17}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}Why Decoder-Only for SVG Captioning?}{17}{subsection.2.2.3}%
\contentsline {section}{\numberline {2.3}Vision-Language Models and Their Limitations}{17}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Vision Transformers (ViT)}{17}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}CLIP: Contrastive Language-Image Pre-training}{18}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}Generative Captioning: BLIP-2 and LLaVA}{19}{subsection.2.3.3}%
\contentsline {subsection}{\numberline {2.3.4}The Vector Graphics Gap}{19}{subsection.2.3.4}%
\contentsline {section}{\numberline {2.4}Positional and Coordinate Encodings}{20}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Sinusoidal Encodings: A Fourier Perspective}{20}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}Application to SVG Coordinates}{21}{subsection.2.4.2}%
\contentsline {section}{\numberline {2.5}Parameter-Efficient Fine-Tuning (PEFT)}{21}{section.2.5}%
\contentsline {subsection}{\numberline {2.5.1}PEFT Methods Overview}{22}{subsection.2.5.1}%
\contentsline {section}{\numberline {2.6}Vector Graphics Generation and Understanding}{23}{section.2.6}%
\contentsline {chapter}{\numberline {3}Methodology}{27}{chapter.3}%
\contentsline {section}{\numberline {3.1}Overview of the Proposed Approach}{27}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}The Naive Approach: Direct Text Input}{27}{subsection.3.1.1}%
\contentsline {subsection}{\numberline {3.1.2}Multimodal Training Process (SPE-LoRA)}{28}{subsection.3.1.2}%
\contentsline {subsection}{\numberline {3.1.3}High-Level Pipeline}{29}{subsection.3.1.3}%
\contentsline {subsection}{\numberline {3.1.4}Design Philosophy}{29}{subsection.3.1.4}%
\contentsline {section}{\numberline {3.2}The Role of Large Language Models in Captioning}{30}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Why Decoder-Only Architectures?}{30}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}Selection of LLM Backbones}{30}{subsection.3.2.2}%
\contentsline {subsection}{\numberline {3.2.3}Zero-Shot Baseline: Why Direct SVG Code Input Fails}{31}{subsection.3.2.3}%
\contentsline {section}{\numberline {3.3}Parameter-Efficient Adaptation via LoRA}{31}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}The Need for Fine-Tuning}{31}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}Low-Rank Adaptation: Mathematical Foundation}{32}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3}Target Modules and Training Strategy}{32}{subsection.3.3.3}%
\contentsline {subsection}{\numberline {3.3.4}Geometric Intuition: Why LoRA Works for Continuous Features}{33}{subsection.3.3.4}%
\contentsline {section}{\numberline {3.4}Embedding Space Architecture}{33}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}Dimensionality Choices}{33}{subsection.3.4.1}%
\contentsline {subsection}{\numberline {3.4.2}Linearization of SVG Scene Graph}{34}{subsection.3.4.2}%
\contentsline {subsubsection}{Standardization Protocol}{34}{section*.13}%
\contentsline {subsection}{\numberline {3.4.3}Concatenation with Text Tokens}{35}{subsection.3.4.3}%
\contentsline {section}{\numberline {3.5}Integration of the SVG Path Embedder}{36}{section.3.5}%
\contentsline {subsection}{\numberline {3.5.1}Discrete Path Embedding Strategy}{36}{subsection.3.5.1}%
\contentsline {subsection}{\numberline {3.5.2}Type and Style Embeddings}{37}{subsection.3.5.2}%
\contentsline {subsection}{\numberline {3.5.3}Multi-Layer Perceptron and Aggregation}{38}{subsection.3.5.3}%
\contentsline {subsection}{\numberline {3.5.4}Projection and Normalization}{38}{subsection.3.5.4}%
\contentsline {section}{\numberline {3.6}Proposed Solution: Vector-Native Processing (SPE + LoRA)}{39}{section.3.6}%
\contentsline {subsection}{\numberline {3.6.1}The SVG Path Embedder (SPE)}{39}{subsection.3.6.1}%
\contentsline {subsubsection}{Architecture: From Discrete Tokens to Continuous Latent Space}{39}{section*.16}%
\contentsline {subsubsection}{Utilization for Captioning}{40}{section*.17}%
\contentsline {subsubsection}{Positional Encoding}{40}{section*.18}%
\contentsline {subsection}{\numberline {3.6.2}Integration with the LLM}{40}{subsection.3.6.2}%
\contentsline {subsection}{\numberline {3.6.3}Context Window and Sequence Length}{41}{subsection.3.6.3}%
\contentsline {subsection}{\numberline {3.6.4}Why SPE + LoRA?}{41}{subsection.3.6.4}%
\contentsline {subsection}{\numberline {3.6.5}Trade-offs: Completeness vs. Context Length}{41}{subsection.3.6.5}%
\contentsline {section}{\numberline {3.7}Context Window Optimization}{42}{section.3.7}%
\contentsline {subsection}{\numberline {3.7.1}The Problem: SVG Verbosity}{42}{subsection.3.7.1}%
\contentsline {subsection}{\numberline {3.7.2}Path Simplification and Filtering}{42}{subsection.3.7.2}%
\contentsline {subsection}{\numberline {3.7.3}Length-Based Filtering}{42}{subsection.3.7.3}%
\contentsline {subsection}{\numberline {3.7.4}Trade-offs: Completeness vs. Context Length}{43}{subsection.3.7.4}%
\contentsline {section}{\numberline {3.8}Training Objective and Loss Function}{43}{section.3.8}%
\contentsline {subsection}{\numberline {3.8.1}Training Objective: Autoregressive Language Modeling}{43}{subsection.3.8.1}%
\contentsline {subsection}{\numberline {3.8.2}Masking Strategy}{44}{subsection.3.8.2}%
\contentsline {section}{\numberline {3.9}Evaluation Metrics}{44}{section.3.9}%
\contentsline {subsection}{\numberline {3.9.1}Visual Alignment: CLIPScore}{44}{subsection.3.9.1}%
\contentsline {subsection}{\numberline {3.9.2}Linguistic Quality and Composite Metrics}{45}{subsection.3.9.2}%
\contentsline {section}{\numberline {3.10}Summary of Methodological Choices}{45}{section.3.10}%
