\babel@toc {english}{}\relax 
\contentsline {chapter}{Abstract}{5}{chapter*.2}%
\contentsline {chapter}{Sommario}{6}{chapter*.3}%
\contentsline {chapter}{\numberline {1}Introduction}{7}{chapter.1}%
\contentsline {section}{\numberline {1.1}The Challenge of Vector Graphics Captioning}{8}{section.1.1}%
\contentsline {section}{\numberline {1.2}Accessibility, Search, and the Need for Automatic Captions}{9}{section.1.2}%
\contentsline {section}{\numberline {1.3}Research Hypothesis: Treating SVG as a Structured Language}{10}{section.1.3}%
\contentsline {section}{\numberline {1.4}The Role of Large Language Models in the Proposed Approach}{11}{section.1.4}%
\contentsline {section}{\numberline {1.5}Parameter-Efficient Fine-Tuning with LoRA}{11}{section.1.5}%
\contentsline {section}{\numberline {1.6}The Spatial Position Encoder: Bridging Geometry and Language}{12}{section.1.6}%
\contentsline {section}{\numberline {1.7}Research Objectives}{13}{section.1.7}%
\contentsline {section}{\numberline {1.8}Summary of Methodology and Key Findings}{13}{section.1.8}%
\contentsline {section}{\numberline {1.9}Thesis Organization}{14}{section.1.9}%
\contentsline {chapter}{\numberline {2}State of the Art}{17}{chapter.2}%
\contentsline {section}{\numberline {2.1}Foundations: Transformers and Self-Attention}{17}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}The Transformer Architecture}{17}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}SVG and the Tokenization Challenge}{19}{subsection.2.1.2}%
\contentsline {section}{\numberline {2.2}Large Language Models: Evolution to Decoder-Only Architectures}{20}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}From BERT to GPT: Encoder vs. Decoder}{20}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Modern Decoder-Only LLMs}{20}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}Why Decoder-Only for SVG Captioning?}{20}{subsection.2.2.3}%
\contentsline {section}{\numberline {2.3}Vision-Language Models and Their Limitations}{21}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Vision Transformers (ViT)}{21}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}CLIP: Contrastive Language-Image Pre-training}{22}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}Generative Captioning: BLIP-2 and LLaVA}{23}{subsection.2.3.3}%
\contentsline {subsection}{\numberline {2.3.4}The Vector Graphics Gap}{23}{subsection.2.3.4}%
\contentsline {section}{\numberline {2.4}Positional and Coordinate Encodings}{23}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Sinusoidal Encodings: A Fourier Perspective}{23}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}Application to SVG Coordinates}{24}{subsection.2.4.2}%
\contentsline {section}{\numberline {2.5}Parameter-Efficient Fine-Tuning (PEFT)}{24}{section.2.5}%
\contentsline {subsection}{\numberline {2.5.1}The Problem: Cost and Forgetting}{24}{subsection.2.5.1}%
\contentsline {subsection}{\numberline {2.5.2}PEFT Methods Overview}{25}{subsection.2.5.2}%
\contentsline {section}{\numberline {2.6}Vector Graphics Generation and Understanding}{26}{section.2.6}%
\contentsline {subsection}{\numberline {2.6.1}Autoregressive and LLM-Based Approaches}{26}{subsection.2.6.1}%
\contentsline {subsubsection}{IconShop and Text-Conditioned Generation}{26}{section*.11}%
\contentsline {subsubsection}{StarVector: Integrating Code and Visuals}{27}{section*.13}%
\contentsline {subsubsection}{vHector: Bridging Geometry and Language}{28}{section*.15}%
\contentsline {subsection}{\numberline {2.6.2}Diffusion-Based Methods}{28}{subsection.2.6.2}%
\contentsline {subsubsection}{VectorFusion: Score Distillation Sampling}{28}{section*.16}%
\contentsline {subsubsection}{SVGDreamer}{29}{section*.18}%
\contentsline {subsection}{\numberline {2.6.3}Representation Learning with Transformers}{29}{subsection.2.6.3}%
\contentsline {subsubsection}{DeepSVG: Hierarchical Generative Networks}{29}{section*.19}%
\contentsline {subsubsection}{SuperSVG and Superpixel Decomposition}{30}{section*.20}%
\contentsline {subsection}{\numberline {2.6.4}Parameter Optimization Approaches}{30}{subsection.2.6.4}%
\contentsline {subsubsection}{LIVE and Differentiable Rasterization}{30}{section*.21}%
\contentsline {subsubsection}{ClipVG}{30}{section*.22}%
\contentsline {subsection}{\numberline {2.6.5}The Gap: From Generation to Captioning}{30}{subsection.2.6.5}%
\contentsline {section}{\numberline {2.7}Summary}{31}{section.2.7}%
\contentsline {chapter}{\numberline {3}Methodology}{33}{chapter.3}%
\contentsline {section}{\numberline {3.1}Overview of the Proposed Approach}{33}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}The Naive Approach: Direct Text Input}{33}{subsection.3.1.1}%
\contentsline {subsection}{\numberline {3.1.2}Baseline Training Process (LoRA-LLM)}{34}{subsection.3.1.2}%
\contentsline {subsection}{\numberline {3.1.3}Multimodal Training Process (SPE-LoRA)}{34}{subsection.3.1.3}%
\contentsline {subsection}{\numberline {3.1.4}High-Level Pipeline}{34}{subsection.3.1.4}%
\contentsline {subsection}{\numberline {3.1.5}Design Philosophy}{36}{subsection.3.1.5}%
\contentsline {section}{\numberline {3.2}The Role of Large Language Models in Captioning}{37}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Why Decoder-Only Architectures?}{37}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}Selection of LLM Backbones}{37}{subsection.3.2.2}%
\contentsline {subsection}{\numberline {3.2.3}Zero-Shot Baseline: Why Direct SVG Code Input Fails}{38}{subsection.3.2.3}%
\contentsline {section}{\numberline {3.3}Parameter-Efficient Adaptation via LoRA}{39}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}The Need for Fine-Tuning}{39}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}Low-Rank Adaptation: Mathematical Foundation}{40}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3}Target Modules and Training Strategy}{40}{subsection.3.3.3}%
\contentsline {subsection}{\numberline {3.3.4}Geometric Intuition: Why LoRA Works for Continuous Features}{41}{subsection.3.3.4}%
\contentsline {section}{\numberline {3.4}Integration of the Spatial Position Encoder}{41}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}Design Requirements}{41}{subsection.3.4.1}%
\contentsline {subsection}{\numberline {3.4.2}Sinusoidal Coordinate Encoding}{42}{subsection.3.4.2}%
\contentsline {subsection}{\numberline {3.4.3}Type and Style Embeddings}{43}{subsection.3.4.3}%
\contentsline {subsection}{\numberline {3.4.4}Multi-Layer Perceptron and Aggregation}{43}{subsection.3.4.4}%
\contentsline {subsection}{\numberline {3.4.5}Projection and Normalization}{43}{subsection.3.4.5}%
\contentsline {section}{\numberline {3.5}Embedding Space Architecture}{46}{section.3.5}%
\contentsline {subsection}{\numberline {3.5.1}Dimensionality Choices}{46}{subsection.3.5.1}%
\contentsline {subsection}{\numberline {3.5.2}Linearization of SVG Scene Graph}{46}{subsection.3.5.2}%
\contentsline {subsection}{\numberline {3.5.3}Concatenation with Text Tokens}{46}{subsection.3.5.3}%
\contentsline {subsection}{\numberline {3.5.4}Attention Mechanism Over Hybrid Sequence}{47}{subsection.3.5.4}%
\contentsline {section}{\numberline {3.6}Context Window Optimization}{47}{section.3.6}%
\contentsline {subsection}{\numberline {3.6.1}The Problem: SVG Verbosity}{47}{subsection.3.6.1}%
\contentsline {subsection}{\numberline {3.6.2}Path Simplification and Filtering}{48}{subsection.3.6.2}%
\contentsline {subsection}{\numberline {3.6.3}Length-Based Filtering}{48}{subsection.3.6.3}%
\contentsline {subsection}{\numberline {3.6.4}Trade-offs: Completeness vs. Context Length}{49}{subsection.3.6.4}%
\contentsline {section}{\numberline {3.7}Training Objective and Loss Function}{49}{section.3.7}%
\contentsline {subsection}{\numberline {3.7.1}Autoregressive Language Modeling}{49}{subsection.3.7.1}%
\contentsline {subsection}{\numberline {3.7.2}Cross-Entropy Loss}{50}{subsection.3.7.2}%
\contentsline {subsection}{\numberline {3.7.3}Masking Strategy}{50}{subsection.3.7.3}%
\contentsline {section}{\numberline {3.8}Evaluation Metrics}{50}{section.3.8}%
\contentsline {subsection}{\numberline {3.8.1}Visual Alignment: CLIPScore}{50}{subsection.3.8.1}%
\contentsline {subsection}{\numberline {3.8.2}Linguistic Quality Metrics}{51}{subsection.3.8.2}%
\contentsline {subsection}{\numberline {3.8.3}Composite Score}{51}{subsection.3.8.3}%
\contentsline {section}{\numberline {3.9}Summary of Methodological Choices}{51}{section.3.9}%
