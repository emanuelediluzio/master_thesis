\begin{thebibliography}{10}

\bibitem{qwen2023}
Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan,
  Wenbin Ge, Yu~Han, Fei Huang, et~al.
\newblock Qwen technical report.
\newblock {\em arXiv preprint arXiv:2309.16609}, 2023.

\bibitem{banerjee2005meteor}
Satanjeev Banerjee and Alon Lavie.
\newblock Meteor: An automatic metric for mt evaluation with improved
  correlation with human judgments.
\newblock {\em Proceedings of the acl workshop on intrinsic and extrinsic
  evaluation measures for machine translation and/or summarization}, pages
  65--72, 2005.

\bibitem{brown2020language}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  et~al.
\newblock Language models are few-shot learners.
\newblock {\em Advances in neural information processing systems},
  33:1877--1901, 2020.

\bibitem{carlier2020deepsvg}
Alexandre Carlier, Martin Danelljan, Alexandre Alahi, and Radu Timofte.
\newblock Deepsvg: A hierarchical generative network for vector graphics
  animation.
\newblock {\em Advances in Neural Information Processing Systems},
  33:16346--16356, 2020.

\bibitem{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock {\em arXiv preprint arXiv:1810.04805}, 2018.

\bibitem{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock {\em arXiv preprint arXiv:2010.11929}, 2020.

\bibitem{hessel2021clipscore}
Jack Hessel, Ari Holtzman, Maxwell Forbes, Ronan~Le Bras, and Yejin Choi.
\newblock Clipscore: A reference-free evaluation metric for image captioning.
\newblock {\em arXiv preprint arXiv:2104.08718}, 2021.

\bibitem{houlsby2019parameter}
Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin
  De~Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly.
\newblock Parameter-efficient transfer learning for nlp.
\newblock {\em International Conference on Machine Learning}, pages 2790--2799,
  2019.

\bibitem{hu2021lora}
Edward~J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean
  Wang, Lu~Wang, and Weizhu Chen.
\newblock Lora: Low-rank adaptation of large language models.
\newblock {\em arXiv preprint arXiv:2106.09685}, 2021.

\bibitem{hu2024supersvg}
Jiaxi Hu et~al.
\newblock Supersvg: Superpixel-based scalable vector graphics synthesis.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 8891--8900, 2024.

\bibitem{jain2023vectorfusion}
Ajay Jain et~al.
\newblock Vectorfusion: Text-to-svg by abstracting pixel-based diffusion
  models.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 1204--1213, 2023.

\bibitem{kaplan2020scaling}
Jared Kaplan, Sam McCandlish, Tom Henighan, Tom~B. Brown, Benjamin Chess, Rewon
  Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei.
\newblock Scaling laws for neural language models.
\newblock {\em arXiv preprint arXiv:2001.08361}, 2020.

\bibitem{li2023blip2}
Junnan Li, Dongxu Li, Savarese Silvio, and Steven Hoi.
\newblock Blip-2: Bootstrapping language-image pre-training with frozen image
  encoders and large language models.
\newblock {\em arXiv preprint arXiv:2301.12597}, 2023.

\bibitem{li2020differentiable}
Tzu-Mao Li, Michal Lukac, Micha{\"e}l Gharbi, and Ragan-Kelley Jonathan.
\newblock Differentiable vector graphics rasterization for editing and
  generative modeling.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 1939--1950, 2020.

\bibitem{li2021prefix}
Xiang~Lisa Li and Percy Liang.
\newblock Prefix-tuning: Optimizing continuous prompts for generation.
\newblock {\em arXiv preprint arXiv:2101.00190}, 2021.

\bibitem{lin2004rouge}
Chin-Yew Lin.
\newblock Rouge: A package for automatic evaluation of summaries.
\newblock {\em Text summarization branches out}, pages 74--81, 2004.

\bibitem{liu2023llava}
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong~Jae Lee.
\newblock Visual instruction tuning.
\newblock {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2023.

\bibitem{ma2022live}
Xu~Ma, Yuqian Zhou, Xingqian Xu, Bin Sun, Dimitar Filev, Nikita Orlov, Yanzhi
  Yuan, and Humphrey Shi.
\newblock Towards layer-wise image vectorization.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 16314--16323, 2022.

\bibitem{mildenhall2020nerf}
Ben Mildenhall, Pratul~P. Srinivasan, Matthew Tancik, Jonathan~T. Barron, Ravi
  Ramamoorthi, and Ren Ng.
\newblock Nerf: Representing scenes as neural radiance fields for view
  synthesis.
\newblock In {\em Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 405--421, 2020.

\bibitem{papineni2002bleu}
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
\newblock Bleu: a method for automatic evaluation of machine translation.
\newblock {\em Proceedings of the 40th annual meeting of the Association for
  Computational Linguistics}, pages 311--318, 2002.

\bibitem{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual representations from natural language
  supervision.
\newblock {\em arXiv preprint arXiv:2103.00020}, 2021.

\bibitem{radford2018improving}
Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et~al.
\newblock Improving language understanding by generative pre-training.
\newblock 2018.

\bibitem{rahaman2019spectral}
Nasim Rahaman, Aristide Baratin, Devansh Arpit, Felix Draxler, Min Lin, Fred~A.
  Hamprecht, Yoshua Bengio, and Aaron~C. Courville.
\newblock On the spectral bias of neural networks.
\newblock {\em Proceedings of the 36th International Conference on Machine
  Learning (ICML)}, pages 5301--5310, 2019.

\bibitem{rodriguez2023starvector}
Camila Rodriguez, Tomaso Bianchi, Priya Shah, and Luca Ferri.
\newblock Starvector: Multimodal svg generation with code-first decoders.
\newblock {\em arXiv preprint arXiv:2311.04567}, 2023.

\bibitem{song2023clipvg}
Jiaxi Song et~al.
\newblock Clipvg: Text-guided vector graphics manipulation.
\newblock {\em Computer Graphics Forum}, 42(7):e14912, 2023.

\bibitem{gemma2024}
Gemma Team.
\newblock Gemma: Open models based on gemini research and technology.
\newblock {\em arXiv preprint arXiv:2403.08295}, 2024.

\bibitem{touvron2023llama}
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine
  Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale,
  et~al.
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock {\em arXiv preprint arXiv:2307.09288}, 2023.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{w3c2011svg}
{W3C}.
\newblock Scalable vector graphics (svg) 1.1 (second edition).
\newblock \url{https://www.w3.org/TR/SVG11/}, 2011.
\newblock Accessed: 2024-01-15.

\bibitem{wu2023iconshop}
Ronghang Wu et~al.
\newblock Iconshop: Text-based vector icon synthesis with autoregressive
  transformers.
\newblock {\em arXiv preprint arXiv:2304.14400}, 2023.

\bibitem{xing2024svgdreamer}
Ximing Xing et~al.
\newblock Svgdreamer: Text guided svg generation with diffusion model.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 7717--7727, 2024.

\bibitem{zhang2019root}
Biao Zhang and Rico Sennrich.
\newblock Root mean square layer normalization.
\newblock {\em Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem{zini2025vhector}
Leonardo Zini, Elia Frigieri, Sebastiano Aloscari, and Lorenzo Baraldi.
\newblock {vH}ector and {H}eisen{V}ec: Scalable vector graphics generation
  through large language models.
\newblock {\em arXiv preprint}, 2025.

\end{thebibliography}
