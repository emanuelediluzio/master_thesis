\relax 
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {chapter}{Abstract}{6}{chapter*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Sommario}{7}{chapter*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{8}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:introduzione}{{1}{8}{Introduction}{chapter.1}{}}
\citation{w3c2011svg}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}The Challenge of Vector Graphics Captioning}{9}{section.1.1}\protected@file@percent }
\newlabel{sec:challenge-vector-captioning}{{1.1}{9}{The Challenge of Vector Graphics Captioning}{section.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Accessibility, Search, and the Need for Automatic Captions}{10}{section.1.2}\protected@file@percent }
\newlabel{sec:motivation-accessibility}{{1.2}{10}{Accessibility, Search, and the Need for Automatic Captions}{section.1.2}{}}
\citation{zini2025vhector}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Research Hypothesis: Treating SVG as a Structured Language}{11}{section.1.3}\protected@file@percent }
\newlabel{sec:hypothesis}{{1.3}{11}{Research Hypothesis: Treating SVG as a Structured Language}{section.1.3}{}}
\citation{hu2021lora}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}The Role of Large Language Models in the Proposed Approach}{12}{section.1.4}\protected@file@percent }
\newlabel{sec:llms-role}{{1.4}{12}{The Role of Large Language Models in the Proposed Approach}{section.1.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Parameter-Efficient Fine-Tuning with LoRA}{12}{section.1.5}\protected@file@percent }
\newlabel{sec:peft-intro}{{1.5}{12}{Parameter-Efficient Fine-Tuning with LoRA}{section.1.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.6}The SVG Path Embedder: Bridging Geometry and Language}{13}{section.1.6}\protected@file@percent }
\newlabel{sec:spe-intro}{{1.6}{13}{The SVG Path Embedder: Bridging Geometry and Language}{section.1.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.7}Research Objectives}{14}{section.1.7}\protected@file@percent }
\newlabel{sec:research-objectives}{{1.7}{14}{Research Objectives}{section.1.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.8}Summary of Methodology and Key Findings}{14}{section.1.8}\protected@file@percent }
\newlabel{sec:summary-methodology}{{1.8}{14}{Summary of Methodology and Key Findings}{section.1.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.9}Thesis Organization}{15}{section.1.9}\protected@file@percent }
\newlabel{sec:thesis-organization}{{1.9}{15}{Thesis Organization}{section.1.9}{}}
\citation{vaswani2017attention}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}State of the Art}{16}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:stato-arte}{{2}{16}{State of the Art}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Foundations: Transformers and Self-Attention}{16}{section.2.1}\protected@file@percent }
\newlabel{sec:dl-foundations}{{2.1}{16}{Foundations: Transformers and Self-Attention}{section.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}The Transformer Architecture}{16}{subsection.2.1.1}\protected@file@percent }
\citation{zhang2019root}
\citation{devlin2018bert}
\citation{radford2018improving,brown2020language}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}SVG and the Tokenization Challenge}{17}{subsection.2.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Large Language Models: Evolution to Decoder-Only Architectures}{17}{section.2.2}\protected@file@percent }
\newlabel{sec:llms-evolution}{{2.2}{17}{Large Language Models: Evolution to Decoder-Only Architectures}{section.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}From BERT to GPT: Encoder vs. Decoder}{17}{subsection.2.2.1}\protected@file@percent }
\citation{touvron2023llama}
\citation{qwen2023}
\citation{gemma2024}
\citation{kaplan2020scaling}
\citation{dosovitskiy2020image}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Modern Decoder-Only LLMs}{18}{subsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Why Decoder-Only for SVG Captioning?}{18}{subsection.2.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Vision-Language Models and Their Limitations}{18}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Vision Transformers (ViT)}{18}{subsection.2.3.1}\protected@file@percent }
\citation{radford2021learning}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces The Vision Transformer (ViT) Architecture. The image is split into patches, linearly projected, and processed by a standard Transformer encoder. (Source: Dosovitskiy et al., 2020)}}{19}{figure.caption.4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:vit-architecture}{{2.1}{19}{The Vision Transformer (ViT) Architecture. The image is split into patches, linearly projected, and processed by a standard Transformer encoder. (Source: Dosovitskiy et al., 2020)}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}CLIP: Contrastive Language-Image Pre-training}{19}{subsection.2.3.2}\protected@file@percent }
\citation{li2023blip2}
\citation{liu2023llava}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Architecture of CLIP (Contrastive Language-Image Pre-training). The model learns to align raster images and text in a shared embedding space, enabling zero-shot transfer to downstream tasks.}}{20}{figure.caption.5}\protected@file@percent }
\newlabel{fig:clip-architecture}{{2.2}{20}{Architecture of CLIP (Contrastive Language-Image Pre-training). The model learns to align raster images and text in a shared embedding space, enabling zero-shot transfer to downstream tasks}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Generative Captioning: BLIP-2 and LLaVA}{20}{subsection.2.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}The Vector Graphics Gap}{20}{subsection.2.3.4}\protected@file@percent }
\citation{vaswani2017attention}
\citation{rahaman2019spectral}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Positional and Coordinate Encodings}{21}{section.2.4}\protected@file@percent }
\newlabel{sec:positional-encodings}{{2.4}{21}{Positional and Coordinate Encodings}{section.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Sinusoidal Encodings: A Fourier Perspective}{21}{subsection.2.4.1}\protected@file@percent }
\newlabel{eq:sinusoidal-encoding}{{2.1}{21}{Sinusoidal Encodings: A Fourier Perspective}{equation.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Application to SVG Coordinates}{22}{subsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Parameter-Efficient Fine-Tuning (PEFT)}{22}{section.2.5}\protected@file@percent }
\newlabel{sec:peft-methods}{{2.5}{22}{Parameter-Efficient Fine-Tuning (PEFT)}{section.2.5}{}}
\citation{houlsby2019parameter}
\citation{li2021prefix}
\citation{hu2021lora}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Visualization of 2D Sinusoidal Positional Encodings. High-frequency components capture fine details, while low-frequency components encode global position, enabling the model to "see" the continuous geometry.}}{23}{figure.caption.6}\protected@file@percent }
\newlabel{fig:2d-pe}{{2.3}{23}{Visualization of 2D Sinusoidal Positional Encodings. High-frequency components capture fine details, while low-frequency components encode global position, enabling the model to "see" the continuous geometry}{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}PEFT Methods Overview}{23}{subsection.2.5.1}\protected@file@percent }
\citation{wu2023iconshop}
\citation{rodriguez2023starvector}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Vector Graphics Generation and Understanding}{24}{section.2.6}\protected@file@percent }
\newlabel{sec:vector-graphics-generation}{{2.6}{24}{Vector Graphics Generation and Understanding}{section.2.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Overview of Autoregressive SVG Generation (IconShop). The model predicts the next drawing command based on the history of previous commands and a text condition. (Source: Wu et al., 2023)}}{24}{figure.caption.7}\protected@file@percent }
\newlabel{fig:iconshop-arch}{{2.4}{24}{Overview of Autoregressive SVG Generation (IconShop). The model predicts the next drawing command based on the history of previous commands and a text condition. (Source: Wu et al., 2023)}{figure.caption.7}{}}
\citation{zini2025vhector}
\citation{jain2023vectorfusion}
\citation{xing2024svgdreamer}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces StarVector Architecture. A dual-encoder system that processes both the raw SVG code and the rendered image to guide generation. (Source: Rodriguez et al., 2023)}}{25}{figure.caption.8}\protected@file@percent }
\newlabel{fig:starvector-arch}{{2.5}{25}{StarVector Architecture. A dual-encoder system that processes both the raw SVG code and the rendered image to guide generation. (Source: Rodriguez et al., 2023)}{figure.caption.8}{}}
\citation{carlier2020deepsvg}
\citation{hu2024supersvg}
\citation{ma2022live}
\citation{li2020differentiable}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces VectorFusion Pipeline. A set of random paths is optimized via Score Distillation Sampling (SDS) from a frozen text-to-image diffusion model. The differentiable rasterizer allows gradients to flow back to the vector parameters. (Source: Jain et al., 2023)}}{26}{figure.caption.9}\protected@file@percent }
\newlabel{fig:vectorfusion-arch}{{2.6}{26}{VectorFusion Pipeline. A set of random paths is optimized via Score Distillation Sampling (SDS) from a frozen text-to-image diffusion model. The differentiable rasterizer allows gradients to flow back to the vector parameters. (Source: Jain et al., 2023)}{figure.caption.9}{}}
\citation{song2023clipvg}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methodology}{28}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:metodologia}{{3}{28}{Methodology}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Overview of the Proposed Approach}{28}{section.3.1}\protected@file@percent }
\newlabel{sec:methodology-overview}{{3.1}{28}{Overview of the Proposed Approach}{section.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}The Naive Approach: Direct Text Input}{28}{subsection.3.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces The Naive Approach: Direct SVG Text Input. The tokenizer fragments continuous coordinates into meaningless sub-tokens, preventing the LLM from grasping the geometric structure.}}{28}{figure.caption.10}\protected@file@percent }
\newlabel{fig:naive-pipeline}{{3.1}{28}{The Naive Approach: Direct SVG Text Input. The tokenizer fragments continuous coordinates into meaningless sub-tokens, preventing the LLM from grasping the geometric structure}{figure.caption.10}{}}
\citation{zini2025vhector}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Intermediate Approach: Text-Only Fine-Tuning. The model is adapted via LoRA to the SVG text format. While it learns to generate valid syntax, it still suffers from the tokenization mismatch and lacks true geometric perception.}}{29}{figure.caption.11}\protected@file@percent }
\newlabel{fig:text-ft-pipeline}{{3.2}{29}{Intermediate Approach: Text-Only Fine-Tuning. The model is adapted via LoRA to the SVG text format. While it learns to generate valid syntax, it still suffers from the tokenization mismatch and lacks true geometric perception}{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Multimodal Training Process (SPE-LoRA)}{29}{subsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}High-Level Pipeline}{30}{subsection.3.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Conceptual overview of the proposed SVG captioning pipeline: (1) Preprocessing, (2) SPE Encoding, (3) LoRA-adapted LLM Processing, (4) Caption Generation.}}{30}{figure.caption.12}\protected@file@percent }
\newlabel{fig:pipeline-overview}{{3.3}{30}{Conceptual overview of the proposed SVG captioning pipeline: (1) Preprocessing, (2) SPE Encoding, (3) LoRA-adapted LLM Processing, (4) Caption Generation}{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}Design Philosophy}{30}{subsection.3.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}The Role of Large Language Models in Captioning}{31}{section.3.2}\protected@file@percent }
\newlabel{sec:llms-methodology}{{3.2}{31}{The Role of Large Language Models in Captioning}{section.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Why Decoder-Only Architectures?}{31}{subsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Selection of LLM Backbones}{31}{subsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Zero-Shot Baseline: Why Direct SVG Code Input Fails}{32}{subsection.3.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Parameter-Efficient Adaptation via LoRA}{32}{section.3.3}\protected@file@percent }
\newlabel{sec:lora-methodology}{{3.3}{32}{Parameter-Efficient Adaptation via LoRA}{section.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}The Need for Fine-Tuning}{32}{subsection.3.3.1}\protected@file@percent }
\citation{hu2021lora}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Low-Rank Adaptation: Mathematical Foundation}{33}{subsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Target Modules and Training Strategy}{33}{subsection.3.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.4}Geometric Intuition: Why LoRA Works for Continuous Features}{34}{subsection.3.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Embedding Space Architecture}{34}{section.3.4}\protected@file@percent }
\newlabel{sec:embedding-architecture}{{3.4}{34}{Embedding Space Architecture}{section.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Dimensionality Choices}{34}{subsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Linearization of SVG Scene Graph}{35}{subsection.3.4.2}\protected@file@percent }
\newlabel{sec:linearization}{{3.4.2}{35}{Linearization of SVG Scene Graph}{subsection.3.4.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{Standardization Protocol}{35}{section*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Concatenation with Text Tokens}{36}{subsection.3.4.3}\protected@file@percent }
\citation{zini2025scalable}
\citation{zini2025vhector}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Concatenation Mechanism. The continuous visual embeddings (green) are prepended to the discrete text embeddings (blue), forming a unified sequence for the transformer. This explicitly shows the "Visual Prefix" strategy.}}{37}{figure.caption.14}\protected@file@percent }
\newlabel{fig:concatenation}{{3.4}{37}{Concatenation Mechanism. The continuous visual embeddings (green) are prepended to the discrete text embeddings (blue), forming a unified sequence for the transformer. This explicitly shows the "Visual Prefix" strategy}{figure.caption.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Integration of the SVG Path Embedder}{37}{section.3.5}\protected@file@percent }
\newlabel{sec:spe-methodology}{{3.5}{37}{Integration of the SVG Path Embedder}{section.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Design Requirements}{37}{subsection.3.5.1}\protected@file@percent }
\citation{mildenhall2020nerf}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Detailed Architecture of the SVG Path Embedder (SPE). In alignment with the underlying code, the system processes discrete tokens rather than raw coordinates. The tokens pass through a shared embedding layer, are augmented with 1D sinusoidal positional encodings, and processed by a standard Transformer Encoder.}}{38}{figure.caption.15}\protected@file@percent }
\newlabel{fig:spe-detailed}{{3.5}{38}{Detailed Architecture of the SVG Path Embedder (SPE). In alignment with the underlying code, the system processes discrete tokens rather than raw coordinates. The tokens pass through a shared embedding layer, are augmented with 1D sinusoidal positional encodings, and processed by a standard Transformer Encoder}{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Sinusoidal Coordinate Encoding}{38}{subsection.3.5.2}\protected@file@percent }
\citation{rahaman2019spectral}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Type and Style Embeddings}{39}{subsection.3.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.4}Multi-Layer Perceptron and Aggregation}{39}{subsection.3.5.4}\protected@file@percent }
\citation{mildenhall2020nerf}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.5}Projection and Normalization}{40}{subsection.3.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Proposed Solution: Vector-Native Processing (SPE + LoRA)}{40}{section.3.6}\protected@file@percent }
\newlabel{sec:proposed-solution-spe-lora}{{3.6}{40}{Proposed Solution: Vector-Native Processing (SPE + LoRA)}{section.3.6}{}}
\citation{vaswani2017attention}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}The SVG Path Embedder (SPE)}{41}{subsection.3.6.1}\protected@file@percent }
\newlabel{sec:spe-design}{{3.6.1}{41}{The SVG Path Embedder (SPE)}{subsection.3.6.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Sequence Embedding and Positional Encoding}{41}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Token Embeddings}{41}{section*.17}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Positional Encoding}{41}{section*.18}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.2}Integration with the LLM}{42}{subsection.3.6.2}\protected@file@percent }
\newlabel{sec:lora-integration}{{3.6.2}{42}{Integration with the LLM}{subsection.3.6.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.3}Context Window and Sequence Length}{42}{subsection.3.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.4}Why SPE + LoRA?}{42}{subsection.3.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.5}Trade-offs: Completeness vs. Context Length}{43}{subsection.3.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Context Window Optimization}{43}{section.3.7}\protected@file@percent }
\newlabel{sec:context-optimization}{{3.7}{43}{Context Window Optimization}{section.3.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.1}The Problem: SVG Verbosity}{43}{subsection.3.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.2}Path Simplification and Filtering}{44}{subsection.3.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.3}Length-Based Filtering}{44}{subsection.3.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.4}Trade-offs: Completeness vs. Context Length}{44}{subsection.3.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.8}Training Objective and Loss Function}{45}{section.3.8}\protected@file@percent }
\newlabel{sec:training-objective}{{3.8}{45}{Training Objective and Loss Function}{section.3.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8.1}Training Objective: Autoregressive Language Modeling}{45}{subsection.3.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8.2}Masking Strategy}{45}{subsection.3.8.2}\protected@file@percent }
\citation{hessel2021clipscore}
\citation{papineni2002bleu}
\citation{banerjee2005meteor}
\citation{lin2004rouge}
\@writefile{toc}{\contentsline {section}{\numberline {3.9}Evaluation Metrics}{46}{section.3.9}\protected@file@percent }
\newlabel{sec:evaluation-metrics-methodology}{{3.9}{46}{Evaluation Metrics}{section.3.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9.1}Visual Alignment: CLIPScore}{46}{subsection.3.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9.2}Linguistic Quality and Composite Metrics}{46}{subsection.3.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.10}Summary of Methodological Choices}{47}{section.3.10}\protected@file@percent }
\newlabel{sec:methodology-summary}{{3.10}{47}{Summary of Methodological Choices}{section.3.10}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Implementation}{48}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:implementazione}{{4}{48}{Implementation}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}System Architecture and Technology Stack}{48}{section.4.1}\protected@file@percent }
\newlabel{sec:system-architecture}{{4.1}{48}{System Architecture and Technology Stack}{section.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Dataset Construction from Raw Chunks}{48}{subsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}SVG Parsing and Linearization}{49}{subsection.4.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Path Simplification Algorithm}{49}{subsection.4.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.4}Dynamic Padding and Collation}{49}{subsection.4.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}The SVG Path Embedder (SPE)}{50}{section.4.2}\protected@file@percent }
\newlabel{sec:spe-implementation}{{4.2}{50}{The SVG Path Embedder (SPE)}{section.4.2}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {4.1}{\ignorespaces Sinusoidal Coordinate Encoding Implementation}}{50}{lstlisting.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}The SPE Module}{51}{subsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}LoRA Integration and Training Loop}{51}{section.4.3}\protected@file@percent }
\newlabel{sec:lora-integration}{{4.3}{51}{LoRA Integration and Training Loop}{section.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Loading the Pre-trained LLM}{51}{subsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Injecting LoRA Adapters}{51}{subsection.4.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Baseline Training Process (LoRA-LLM)}{51}{subsection.4.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Multimodal Training Process (SPE-LoRA)}{52}{subsection.4.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Challenges and Solutions}{52}{section.4.4}\protected@file@percent }
\newlabel{sec:challenges}{{4.4}{52}{Challenges and Solutions}{section.4.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Addressing Gradient Explosion}{52}{subsection.4.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Library Compatibility}{53}{subsection.4.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}WandB Integration}{53}{subsection.4.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces WandB dashboard showing training loss, evaluation loss, and system metrics (GPU utilization) during the fine-tuning of the SPE + Qwen2-7B model.}}{53}{figure.caption.19}\protected@file@percent }
\newlabel{fig:wandb}{{4.1}{53}{WandB dashboard showing training loss, evaluation loss, and system metrics (GPU utilization) during the fine-tuning of the SPE + Qwen2-7B model}{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.4}Hyperparameters and Training Details}{53}{subsection.4.4.4}\protected@file@percent }
\newlabel{sec:hyperparameters}{{4.4.4}{53}{Hyperparameters and Training Details}{subsection.4.4.4}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Experimental Evaluation}{55}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:valutazione}{{5}{55}{Experimental Evaluation}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Experimental Setup}{55}{section.5.1}\protected@file@percent }
\newlabel{sec:experimental-setup}{{5.1}{55}{Experimental Setup}{section.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Dataset Curation: The Icons8 Benchmark}{55}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Stratified Splitting}{55}{section*.20}\protected@file@percent }
\citation{papineni2002bleu}
\citation{banerjee2005meteor}
\citation{lin2004rouge}
\citation{hessel2021clipscore}
\citation{li2023blip2}
\citation{xiao2023florence}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Evaluation Metrics}{56}{subsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Linguistic Metrics (Reference-Based)}{56}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Visual-Semantic Metric (Reference-Free)}{56}{section*.22}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Composite Score}{56}{section*.23}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}Baselines and Models}{56}{subsection.5.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Quantitative Results}{57}{section.5.2}\protected@file@percent }
\newlabel{sec:quantitative-results}{{5.2}{57}{Quantitative Results}{section.5.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Main Results on Icons8 Test Set (400 samples). Best results in \textbf  {bold}.}}{57}{table.caption.24}\protected@file@percent }
\newlabel{tab:main-results}{{5.1}{57}{Main Results on Icons8 Test Set (400 samples). Best results in \textbf {bold}}{table.caption.24}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Analysis of Results}{57}{subsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Ablation Studies}{58}{section.5.3}\protected@file@percent }
\newlabel{sec:ablation-studies}{{5.3}{58}{Ablation Studies}{section.5.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Ablation: Feature Normalization}}{58}{table.caption.25}\protected@file@percent }
\newlabel{tab:ablation-norm}{{5.2}{58}{Ablation: Feature Normalization}{table.caption.25}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}LoRA Rank}{58}{subsection.5.3.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces Ablation: LoRA Rank}}{58}{table.caption.26}\protected@file@percent }
\newlabel{tab:ablation-rank}{{5.3}{58}{Ablation: LoRA Rank}{table.caption.26}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Qualitative Analysis}{59}{section.5.4}\protected@file@percent }
\newlabel{sec:qualitative-analysis}{{5.4}{59}{Qualitative Analysis}{section.5.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Success Cases}{59}{subsection.5.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Qualitative Comparison. My model (SPE+LoRA) generates accurate, descriptive captions. The Zero-Shot text baseline either fails to generate text (repeating coordinates) or hallucinates common shapes due to lack of visual grounding.}}{59}{figure.caption.27}\protected@file@percent }
\newlabel{fig:qualitative-comparison}{{5.1}{59}{Qualitative Comparison. My model (SPE+LoRA) generates accurate, descriptive captions. The Zero-Shot text baseline either fails to generate text (repeating coordinates) or hallucinates common shapes due to lack of visual grounding}{figure.caption.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Failure Modes and Error Taxonomy}{59}{subsection.5.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{1. Geometric Hallucination}{60}{section*.28}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{2. Attribute Mismatch}{60}{section*.29}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{3. OCR Failure}{60}{section*.30}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{4. Abstract Concept Failure}{60}{section*.31}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.3}Qualitative Gallery}{60}{subsection.5.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Sample 0: User Interface}}{61}{figure.caption.32}\protected@file@percent }
\newlabel{fig:gallery_0}{{5.2}{61}{Sample 0: User Interface}{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Sample 1: Arrow}}{62}{figure.caption.33}\protected@file@percent }
\newlabel{fig:gallery_1}{{5.3}{62}{Sample 1: Arrow}{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Sample 2: Weather}}{63}{figure.caption.34}\protected@file@percent }
\newlabel{fig:gallery_2}{{5.4}{63}{Sample 2: Weather}{figure.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Sample 3: Social Media}}{64}{figure.caption.35}\protected@file@percent }
\newlabel{fig:gallery_3}{{5.5}{64}{Sample 3: Social Media}{figure.caption.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Sample 4: Document}}{65}{figure.caption.36}\protected@file@percent }
\newlabel{fig:gallery_4}{{5.6}{65}{Sample 4: Document}{figure.caption.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Sample 5: Search}}{66}{figure.caption.37}\protected@file@percent }
\newlabel{fig:gallery_5}{{5.7}{66}{Sample 5: Search}{figure.caption.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Sample 6: Home}}{67}{figure.caption.38}\protected@file@percent }
\newlabel{fig:gallery_6}{{5.8}{67}{Sample 6: Home}{figure.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Sample 7: User}}{68}{figure.caption.39}\protected@file@percent }
\newlabel{fig:gallery_7}{{5.9}{68}{Sample 7: User}{figure.caption.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces Sample 8: Mail}}{69}{figure.caption.40}\protected@file@percent }
\newlabel{fig:gallery_8}{{5.10}{69}{Sample 8: Mail}{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces Sample 9: Abstract}}{70}{figure.caption.41}\protected@file@percent }
\newlabel{fig:gallery_9}{{5.11}{70}{Sample 9: Abstract}{figure.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces Sample 10: User Interface Element}}{71}{figure.caption.42}\protected@file@percent }
\newlabel{fig:gallery_10}{{5.12}{71}{Sample 10: User Interface Element}{figure.caption.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.13}{\ignorespaces Sample 11: Medical Icon}}{72}{figure.caption.43}\protected@file@percent }
\newlabel{fig:gallery_11}{{5.13}{72}{Sample 11: Medical Icon}{figure.caption.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.14}{\ignorespaces Sample 12: Education}}{73}{figure.caption.44}\protected@file@percent }
\newlabel{fig:gallery_12}{{5.14}{73}{Sample 12: Education}{figure.caption.44}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.15}{\ignorespaces Sample 13: Food}}{74}{figure.caption.45}\protected@file@percent }
\newlabel{fig:gallery_13}{{5.15}{74}{Sample 13: Food}{figure.caption.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.16}{\ignorespaces Sample 14: Finance}}{75}{figure.caption.46}\protected@file@percent }
\newlabel{fig:gallery_14}{{5.16}{75}{Sample 14: Finance}{figure.caption.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.17}{\ignorespaces Sample 15: Transport}}{76}{figure.caption.47}\protected@file@percent }
\newlabel{fig:gallery_15}{{5.17}{76}{Sample 15: Transport}{figure.caption.47}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.18}{\ignorespaces Sample 16: Music}}{77}{figure.caption.48}\protected@file@percent }
\newlabel{fig:gallery_16}{{5.18}{77}{Sample 16: Music}{figure.caption.48}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.19}{\ignorespaces Sample 17: Security}}{78}{figure.caption.49}\protected@file@percent }
\newlabel{fig:gallery_17}{{5.19}{78}{Sample 17: Security}{figure.caption.49}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.20}{\ignorespaces Sample 18: Shopping}}{79}{figure.caption.50}\protected@file@percent }
\newlabel{fig:gallery_18}{{5.20}{79}{Sample 18: Shopping}{figure.caption.50}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.21}{\ignorespaces Sample 19: Settings}}{80}{figure.caption.51}\protected@file@percent }
\newlabel{fig:gallery_19}{{5.21}{80}{Sample 19: Settings}{figure.caption.51}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.22}{\ignorespaces Sample 20: Location}}{81}{figure.caption.52}\protected@file@percent }
\newlabel{fig:gallery_20}{{5.22}{81}{Sample 20: Location}{figure.caption.52}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.23}{\ignorespaces Sample 21: Multimedia}}{82}{figure.caption.53}\protected@file@percent }
\newlabel{fig:gallery_21}{{5.23}{82}{Sample 21: Multimedia}{figure.caption.53}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Discussion}{83}{section.5.5}\protected@file@percent }
\newlabel{sec:discussion}{{5.5}{83}{Discussion}{section.5.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Summary}{83}{section.5.6}\protected@file@percent }
\citation{zini2025vhector}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusions and Future Work}{84}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:conclusioni}{{6}{84}{Conclusions and Future Work}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Summary of the Research Journey}{84}{section.6.1}\protected@file@percent }
\newlabel{sec:research-journey}{{6.1}{84}{Summary of the Research Journey}{section.6.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Main Contributions Revisited}{85}{section.6.2}\protected@file@percent }
\newlabel{sec:contributions-revisited}{{6.2}{85}{Main Contributions Revisited}{section.6.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Empirical Contributions}{85}{subsection.6.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}Practical Contributions}{86}{subsection.6.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Empirical Findings and Insights}{86}{section.6.3}\protected@file@percent }
\newlabel{sec:empirical-insights}{{6.3}{86}{Empirical Findings and Insights}{section.6.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Limitations}{86}{section.6.4}\protected@file@percent }
\newlabel{sec:limitations-conclusions}{{6.4}{86}{Limitations}{section.6.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.1}Technical Limitations}{86}{subsection.6.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.2}Dataset and Domain Limitations}{87}{subsection.6.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.3}Evaluation Limitations}{87}{subsection.6.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Ethical Considerations and Responsible Deployment}{87}{section.6.5}\protected@file@percent }
\newlabel{sec:ethical-considerations-conclusions}{{6.5}{87}{Ethical Considerations and Responsible Deployment}{section.6.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.6}Future Research Directions}{87}{section.6.6}\protected@file@percent }
\newlabel{sec:future-work}{{6.6}{87}{Future Research Directions}{section.6.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.1}Architectural Extensions}{87}{subsection.6.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Hierarchical Spatial Encoders}{87}{section*.54}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Multi-Scale Feature Fusion}{88}{section*.55}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Hybrid Raster-Vector Encoders}{88}{section*.56}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{OCR Integration}{88}{section*.57}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.2}Dataset and Domain Expansion}{88}{subsection.6.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Technical Diagrams and Data Visualizations}{88}{section*.58}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Cross-Dataset Generalization}{88}{section*.59}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Multilingual Captions}{89}{section*.60}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Synthetic Data Generation}{89}{section*.61}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.3}Multimodal Pretraining}{89}{subsection.6.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{SVG-Image Contrastive Learning}{89}{section*.62}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Joint SVG-Text-Image Pretraining}{89}{section*.63}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Masked SVG Modeling}{89}{section*.64}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.4}Interactive Systems and Applications}{89}{subsection.6.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Design Tool Integration}{89}{section*.65}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Semantic Search for Icon Libraries}{90}{section*.66}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Interactive Refinement}{90}{section*.67}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Multimodal Dialogue}{90}{section*.68}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.5}Evaluation Methodology}{90}{subsection.6.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Human Evaluation at Scale}{90}{section*.69}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{User Studies with Visually Impaired Participants}{90}{section*.70}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Benchmarking on Standardized Suites}{90}{section*.71}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Robustness and Adversarial Evaluation}{91}{section*.72}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.6}Broader Vision: End-to-End Vector-Language Systems}{91}{subsection.6.6.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.7}Closing Remarks}{91}{section.6.7}\protected@file@percent }
\newlabel{sec:closing-remarks}{{6.7}{91}{Closing Remarks}{section.6.7}{}}
\bibstyle{plain}
\bibdata{bibliography}
\@writefile{toc}{\contentsline {chapter}{Acknowledgements}{93}{chapter*.73}\protected@file@percent }
\bibcite{qwen2023}{1}
\bibcite{banerjee2005meteor}{2}
\bibcite{brown2020language}{3}
\bibcite{carlier2020deepsvg}{4}
\bibcite{devlin2018bert}{5}
\bibcite{dosovitskiy2020image}{6}
\bibcite{hessel2021clipscore}{7}
\bibcite{houlsby2019parameter}{8}
\bibcite{hu2021lora}{9}
\bibcite{hu2024supersvg}{10}
\bibcite{jain2023vectorfusion}{11}
\bibcite{kaplan2020scaling}{12}
\bibcite{li2023blip2}{13}
\bibcite{li2020differentiable}{14}
\bibcite{li2021prefix}{15}
\bibcite{lin2004rouge}{16}
\bibcite{liu2023llava}{17}
\bibcite{ma2022live}{18}
\bibcite{mildenhall2020nerf}{19}
\bibcite{papineni2002bleu}{20}
\bibcite{radford2021learning}{21}
\bibcite{radford2018improving}{22}
\bibcite{rahaman2019spectral}{23}
\bibcite{rodriguez2023starvector}{24}
\bibcite{song2023clipvg}{25}
\bibcite{gemma2024}{26}
\bibcite{touvron2023llama}{27}
\bibcite{vaswani2017attention}{28}
\bibcite{w3c2011svg}{29}
\bibcite{wu2023iconshop}{30}
\bibcite{xiao2023florence}{31}
\bibcite{xing2024svgdreamer}{32}
\bibcite{zhang2019root}{33}
\bibcite{zini2025vhector}{34}
\gdef \@abspage@last{97}
